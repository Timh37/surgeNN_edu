{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b40ee5-e7ea-4d42-a44c-8ac36c38fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from surgeNN import io\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem() #list stores, stripp zarr from filename, load "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b1512-2d82-46b3-8b84-b72d35b9f402",
   "metadata": {},
   "source": [
    "Counts number of samples and threshold exceedances in each split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d28f803-2f4d-4a73-a8af-1d6b73a88f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the script\n",
    "tgs        = ['stavanger-svg-nor-nhs.csv','wick-wic-gbr-bodc.csv','esbjerg-esb-dnk-dmi.csv','immingham-imm-gbr-bodc.csv','den_helder-denhdr-nld-rws.csv', 'fishguard-fis-gbr-bodc.csv',  'brest-822a-fra-uhslc.csv', 'vigo-vigo-esp-ieo.csv',  'alicante_i_outer_harbour-alio-esp-da_mm.csv']\n",
    "tgnames = ['Stavanger (NOR)','Wick (UK)', 'Esbjerg (DK)','Immingham (UK)','Den Helder (NL)','Fishguard (UK)','Brest (FR)','Vigo (PT)', 'Alicante (SP)']\n",
    "\n",
    "qnts = np.array([.95,.98,.99,.995]) #quantiles, don't touch\n",
    "\n",
    "max_timesteps_between_extremes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4884ba0e-e278-484e-8384-d42f364b7995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/backends/api.py:982: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  datasets = [open_(p, **open_kwargs) for p in paths]\n"
     ]
    }
   ],
   "source": [
    "lstms = io.Output('gs://leap-persistent/timh37/surgeNN_output/nns/performance_modified_v2/lstm')\n",
    "#lstms = io.Output('/home/jovyan/test_surge_models/results/nns_v2/performance/lstm')\n",
    "lstms.open_performance_data(tgs)\n",
    "lstms.data = lstms.data.sel(max_timesteps_between_extremes=max_timesteps_between_extremes).load()\n",
    "\n",
    "#compute metrics for observations (it,i doesn't matter as long as all models have been run with the same n_t)\n",
    "observed_thresholds = lstms.data.o.isel(it=0).quantile(np.array([.95,.98,.99,.999]),dim='time')\n",
    "observed_stds = lstms.observed_stds()\n",
    "\n",
    "lstms=lstms.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc33f6c-801e-4e2e-8c71-6a27bf8b6bba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stavanger-svg-nor-nhs.csv\n",
      "total\n",
      "train: 65084[0.592], val: 23178[0.211], test: 21697[0.197]\n",
      "99th %ile: [0.35030577 0.35051451 0.35015658]\n",
      "num exceedances: [651 232 217]\n",
      "num filtered exceedances: [586 199 190]\n",
      "99.9th %ile: [0.53453608 0.50878325 0.54609422]\n",
      "num exceedances: [66 24 22]\n",
      "num filtered exceedances: [66 24 22]\n",
      "\n",
      "wick-wic-gbr-bodc.csv\n",
      "total\n",
      "train: 57822[0.605], val: 21538[0.225], test: 16200[0.170]\n",
      "99th %ile: [0.42810703 0.43036838 0.41434328]\n",
      "num exceedances: [579 216 162]\n",
      "num filtered exceedances: [516 192 138]\n",
      "99.9th %ile: [0.62785725 0.62971791 0.6080498 ]\n",
      "num exceedances: [58 22 17]\n",
      "num filtered exceedances: [58 22 17]\n",
      "\n",
      "esbjerg-esb-dnk-dmi.csv\n",
      "total\n",
      "train: 62889[0.602], val: 20239[0.194], test: 21364[0.204]\n",
      "99th %ile: [1.06475585 1.08536515 1.09898876]\n",
      "num exceedances: [629 203 214]\n",
      "num filtered exceedances: [572 187 192]\n",
      "99.9th %ile: [1.84939663 1.68724452 1.71996548]\n",
      "num exceedances: [63 21 22]\n",
      "num filtered exceedances: [63 21 22]\n",
      "\n",
      "immingham-imm-gbr-bodc.csv\n",
      "total\n",
      "train: 52939[0.567], val: 20280[0.217], test: 20164[0.216]\n",
      "99th %ile: [0.56077358 0.57074676 0.55588326]\n",
      "num exceedances: [530 203 202]\n",
      "num filtered exceedances: [403 153 159]\n",
      "99.9th %ile: [1.01374146 0.92575845 0.99736043]\n",
      "num exceedances: [53 21 21]\n",
      "num filtered exceedances: [51 20 20]\n",
      "\n",
      "den_helder-denhdr-nld-rws.csv\n",
      "total\n",
      "train: 66475[0.587], val: 23368[0.206], test: 23376[0.206]\n",
      "99th %ile: [0.8091189  0.79513056 0.8010364 ]\n",
      "num exceedances: [665 234 234]\n",
      "num filtered exceedances: [593 206 200]\n",
      "99.9th %ile: [1.39685971 1.25909681 1.38605368]\n",
      "num exceedances: [67 24 24]\n",
      "num filtered exceedances: [67 24 24]\n",
      "\n",
      "fishguard-fis-gbr-bodc.csv\n",
      "total\n",
      "train: 57995[0.606], val: 18361[0.192], test: 19284[0.202]\n",
      "99th %ile: [0.38350331 0.39146762 0.39105862]\n",
      "num exceedances: [580 184 193]\n",
      "num filtered exceedances: [475 153 156]\n",
      "99.9th %ile: [0.58702381 0.63579026 0.64826991]\n",
      "num exceedances: [58 19 20]\n",
      "num filtered exceedances: [55 19 18]\n",
      "\n",
      "brest-822a-fra-uhslc.csv\n",
      "total\n",
      "train: 67810[0.601], val: 21738[0.193], test: 23304[0.207]\n",
      "99th %ile: [0.35234436 0.35255661 0.36026537]\n",
      "num exceedances: [679 218 234]\n",
      "num filtered exceedances: [577 169 195]\n",
      "99.9th %ile: [0.55445532 0.53039519 0.58936334]\n",
      "num exceedances: [68 22 24]\n",
      "num filtered exceedances: [65 19 23]\n",
      "\n",
      "vigo-vigo-esp-ieo.csv\n",
      "total\n",
      "train: 59772[0.568], val: 22775[0.216], test: 22663[0.215]\n",
      "99th %ile: [0.29454366 0.28565592 0.299766  ]\n",
      "num exceedances: [598 228 227]\n",
      "num filtered exceedances: [487 168 207]\n",
      "99.9th %ile: [0.44915861 0.42460961 0.44660791]\n",
      "num exceedances: [60 23 23]\n",
      "num filtered exceedances: [53 16 23]\n",
      "\n",
      "alicante_i_outer_harbour-alio-esp-da_mm.csv\n",
      "total\n",
      "train: 53578[0.596], val: 16692[0.186], test: 19671[0.219]\n",
      "99th %ile: [0.2033614  0.19520363 0.19990437]\n",
      "num exceedances: [536 167 197]\n",
      "num filtered exceedances: [493 154 182]\n",
      "99.9th %ile: [0.29216954 0.2777056  0.30891965]\n",
      "num exceedances: [54 17 20]\n",
      "num filtered exceedances: [53 17 20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tg in lstms.tg:\n",
    "    num_train_samples = np.sum(np.isfinite(lstms.sel(tg=tg).yhat.isel(it=0,i=0).sel(split='train')*lstms.sel(tg=tg).o.isel(it=0).sel(split='train'))).values\n",
    "    num_val_samples = np.sum(np.isfinite(lstms.sel(tg=tg).yhat.isel(it=0,i=0).sel(split='val')*lstms.sel(tg=tg).o.isel(it=0).sel(split='val'))).values\n",
    "    num_test_samples = np.sum(np.isfinite(lstms.sel(tg=tg).yhat.isel(it=0,i=0).sel(split='test')*lstms.sel(tg=tg).o.isel(it=0).sel(split='test'))).values\n",
    "\n",
    "    num_total_samples = num_train_samples + num_val_samples + num_test_samples\n",
    "    \n",
    "    print(tg.values)\n",
    "    print('total')\n",
    "    print('train: '+str(num_train_samples)+'['+'{0:.3f}'.format(num_train_samples/num_total_samples)+']'+', val: ' + str(num_val_samples) + '['+'{0:.3f}'.format(num_val_samples/num_total_samples)+']'+', test: '+str(num_test_samples)+'['+'{0:.3f}'.format(num_test_samples/num_total_samples)+']' )\n",
    "    where_exceedances_99 = (lstms.o>=observed_thresholds.sel(quantile=.99)).sel(tg=tg).isel(it=0)\n",
    "    where_exceedances_99p9 = (lstms.o>=observed_thresholds.sel(quantile=.999)).sel(tg=tg).isel(it=0)\n",
    "    \n",
    "    print('99th %ile: '+str(observed_thresholds.sel(quantile=.99).sel(tg=tg).values))\n",
    "    print('num exceedances: '+str(where_exceedances_99.sum(dim='time').values))\n",
    "    print('num filtered exceedances: '+str(((where_exceedances_99) & (where_exceedances_99.rolling(time=1+2*3,center='True').sum()>1)).sum(dim='time').values))\n",
    "    print('99.9th %ile: '+str(observed_thresholds.sel(quantile=.999).sel(tg=tg).values))\n",
    "    print('num exceedances: '+str(where_exceedances_99p9.sum(dim='time').values))\n",
    "    print('num filtered exceedances: '+str(((where_exceedances_99p9) & (where_exceedances_99.rolling(time=1+2*3,center='True').sum()>1)).sum(dim='time').values))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b4f8b-c1bc-422c-a41f-01c7767a060e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
